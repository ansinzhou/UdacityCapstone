{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('capstone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>ShortBuy</th>\n",
       "      <th>ShortBuy Label</th>\n",
       "      <th>ZhanDVAR</th>\n",
       "      <th>ZhanDVAR Label</th>\n",
       "      <th>TwoDvar</th>\n",
       "      <th>TwoDvar Label</th>\n",
       "      <th>100RDVAR</th>\n",
       "      <th>...</th>\n",
       "      <th>high/dvar</th>\n",
       "      <th>high/dvar Label</th>\n",
       "      <th>MACDVdh</th>\n",
       "      <th>MACDVdh Label</th>\n",
       "      <th>high/open</th>\n",
       "      <th>high/open Label</th>\n",
       "      <th>open/q</th>\n",
       "      <th>open/q Label</th>\n",
       "      <th>BuyWINLOSS</th>\n",
       "      <th>BuyWINLOSS Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JBLU</td>\n",
       "      <td>8/21/2007</td>\n",
       "      <td>4:00 PM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.71</td>\n",
       "      <td>...</td>\n",
       "      <td>1.140826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.987220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.635748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JBLU</td>\n",
       "      <td>8/22/2007</td>\n",
       "      <td>4:00 PM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.71</td>\n",
       "      <td>...</td>\n",
       "      <td>1.140826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.876923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JBLU</td>\n",
       "      <td>8/23/2007</td>\n",
       "      <td>4:00 PM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.71</td>\n",
       "      <td>...</td>\n",
       "      <td>1.140826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.906736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JBLU</td>\n",
       "      <td>8/24/2007</td>\n",
       "      <td>4:00 PM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.71</td>\n",
       "      <td>...</td>\n",
       "      <td>1.140826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.965116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JBLU</td>\n",
       "      <td>8/27/2007</td>\n",
       "      <td>4:00 PM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.71</td>\n",
       "      <td>...</td>\n",
       "      <td>1.140826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.968254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.639810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol       Date     Time  ShortBuy  ShortBuy Label  ZhanDVAR  \\\n",
       "0   JBLU  8/21/2007  4:00 PM       0.0             NaN     1.055   \n",
       "1   JBLU  8/22/2007  4:00 PM       0.0             NaN     1.055   \n",
       "2   JBLU  8/23/2007  4:00 PM       0.0             NaN     1.055   \n",
       "3   JBLU  8/24/2007  4:00 PM       0.0             NaN     1.055   \n",
       "4   JBLU  8/27/2007  4:00 PM       0.0             NaN     1.055   \n",
       "\n",
       "   ZhanDVAR Label  TwoDvar  TwoDvar Label  100RDVAR  ...  high/dvar  \\\n",
       "0             NaN     1.52            NaN      1.71  ...   1.140826   \n",
       "1             NaN     1.52            NaN      1.71  ...   1.140826   \n",
       "2             NaN     1.52            NaN      1.71  ...   1.140826   \n",
       "3             NaN     1.52            NaN      1.71  ...   1.140826   \n",
       "4             NaN     1.52            NaN      1.71  ...   1.140826   \n",
       "\n",
       "   high/dvar Label  MACDVdh  MACDVdh Label  high/open  high/open Label  \\\n",
       "0              NaN      1.0            NaN   2.987220              NaN   \n",
       "1              NaN      1.0            NaN   2.876923              NaN   \n",
       "2              NaN      1.0            NaN   2.906736              NaN   \n",
       "3              NaN      1.0            NaN   2.965116              NaN   \n",
       "4              NaN      1.0            NaN   2.968254              NaN   \n",
       "\n",
       "     open/q  open/q Label  BuyWINLOSS  BuyWINLOSS Label  \n",
       "0  0.635748           NaN         0.0               NaN  \n",
       "1  0.660122           NaN         0.0               NaN  \n",
       "2  0.653351           NaN         0.0               NaN  \n",
       "3  0.640487           NaN         0.0               NaN  \n",
       "4  0.639810           NaN         0.0               NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 716701 entries, 0 to 716700\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Symbol             716701 non-null  object \n",
      " 1   Date               716701 non-null  object \n",
      " 2   Time               716701 non-null  object \n",
      " 3   ShortBuy           716629 non-null  float64\n",
      " 4   ShortBuy Label     0 non-null       float64\n",
      " 5   ZhanDVAR           680559 non-null  float64\n",
      " 6   ZhanDVAR Label     0 non-null       float64\n",
      " 7   TwoDvar            680073 non-null  float64\n",
      " 8   TwoDvar Label      0 non-null       float64\n",
      " 9   100RDVAR           677502 non-null  float64\n",
      " 10  100RDVAR Label     0 non-null       float64\n",
      " 11  MA5Anewhigh        716639 non-null  float64\n",
      " 12  MA5Anewhigh Label  0 non-null       float64\n",
      " 13  high/dvar          674059 non-null  float64\n",
      " 14  high/dvar Label    0 non-null       float64\n",
      " 15  MACDVdh            575582 non-null  float64\n",
      " 16  MACDVdh Label      0 non-null       float64\n",
      " 17  high/open          574390 non-null  float64\n",
      " 18  high/open Label    0 non-null       float64\n",
      " 19  open/q             670809 non-null  float64\n",
      " 20  open/q Label       0 non-null       float64\n",
      " 21  BuyWINLOSS         714280 non-null  float64\n",
      " 22  BuyWINLOSS Label   0 non-null       float64\n",
      "dtypes: float64(20), object(3)\n",
      "memory usage: 125.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShortBuy</th>\n",
       "      <th>ShortBuy Label</th>\n",
       "      <th>ZhanDVAR</th>\n",
       "      <th>ZhanDVAR Label</th>\n",
       "      <th>TwoDvar</th>\n",
       "      <th>TwoDvar Label</th>\n",
       "      <th>100RDVAR</th>\n",
       "      <th>100RDVAR Label</th>\n",
       "      <th>MA5Anewhigh</th>\n",
       "      <th>MA5Anewhigh Label</th>\n",
       "      <th>high/dvar</th>\n",
       "      <th>high/dvar Label</th>\n",
       "      <th>MACDVdh</th>\n",
       "      <th>MACDVdh Label</th>\n",
       "      <th>high/open</th>\n",
       "      <th>high/open Label</th>\n",
       "      <th>open/q</th>\n",
       "      <th>open/q Label</th>\n",
       "      <th>BuyWINLOSS</th>\n",
       "      <th>BuyWINLOSS Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>716629.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>680559.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>680073.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>677502.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>716639.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>674059.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>575582.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>574390.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>670809.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>714280.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.088047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.528723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.147524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.806758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.615768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.242789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.021454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.565248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.160618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.479511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.243195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.127405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016731</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.911482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.045695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.062682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.640000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.131579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.046169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.001502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.094858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.305466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.596696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.209910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.098039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.080000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.060000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>463.833300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2655.173000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290.769200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ShortBuy  ShortBuy Label       ZhanDVAR  ZhanDVAR Label  \\\n",
       "count  716629.000000             0.0  680559.000000             0.0   \n",
       "mean        0.000460             NaN       1.088047             NaN   \n",
       "std         0.021454             NaN       0.103610             NaN   \n",
       "min         0.000000             NaN       0.911482             NaN   \n",
       "25%         0.000000             NaN       1.045695             NaN   \n",
       "50%         0.000000             NaN       1.062682             NaN   \n",
       "75%         0.000000             NaN       1.094858             NaN   \n",
       "max         1.000000             NaN       3.098039             NaN   \n",
       "\n",
       "         TwoDvar  TwoDvar Label       100RDVAR  100RDVAR Label    MA5Anewhigh  \\\n",
       "count  680073.00            0.0  677502.000000             0.0  716639.000000   \n",
       "mean         inf            NaN       3.528723             NaN       1.147524   \n",
       "std          NaN            NaN       3.565248             NaN       0.160618   \n",
       "min         0.00            NaN       0.000000             NaN       0.200000   \n",
       "25%         1.71            NaN       2.010000             NaN       1.090000   \n",
       "50%         2.04            NaN       2.640000             NaN       1.120000   \n",
       "75%         2.96            NaN       3.820000             NaN       1.180000   \n",
       "max          inf            NaN      79.080000             NaN      53.060000   \n",
       "\n",
       "       MA5Anewhigh Label      high/dvar  high/dvar Label    MACDVdh  \\\n",
       "count                0.0  674059.000000              0.0  575582.00   \n",
       "mean                 NaN       1.806758              NaN        NaN   \n",
       "std                  NaN      11.479511              NaN        NaN   \n",
       "min                  NaN       0.099808              NaN       -inf   \n",
       "25%                  NaN       1.000000              NaN      -1.43   \n",
       "50%                  NaN       1.131579              NaN       1.13   \n",
       "75%                  NaN       1.305466              NaN       2.63   \n",
       "max                  NaN     463.833300              NaN        inf   \n",
       "\n",
       "       MACDVdh Label      high/open  high/open Label         open/q  \\\n",
       "count            0.0  574390.000000              0.0  670809.000000   \n",
       "mean             NaN       2.615768              NaN       1.242789   \n",
       "std              NaN      28.243195              NaN       6.127405   \n",
       "min              NaN       0.032787              NaN       0.000000   \n",
       "25%              NaN       0.734591              NaN       0.777065   \n",
       "50%              NaN       1.046169              NaN       1.001502   \n",
       "75%              NaN       1.596696              NaN       1.209910   \n",
       "max              NaN    2655.173000              NaN     290.769200   \n",
       "\n",
       "       open/q Label     BuyWINLOSS  BuyWINLOSS Label  \n",
       "count           0.0  714280.000000               0.0  \n",
       "mean            NaN       0.000280               NaN  \n",
       "std             NaN       0.016731               NaN  \n",
       "min             NaN       0.000000               NaN  \n",
       "25%             NaN       0.000000               NaN  \n",
       "50%             NaN       0.000000               NaN  \n",
       "75%             NaN       0.000000               NaN  \n",
       "max             NaN       1.000000               NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 716701 entries, 0 to 716700\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Symbol       716701 non-null  object \n",
      " 1   Date         716701 non-null  object \n",
      " 2   Time         716701 non-null  object \n",
      " 3   ShortBuy     716629 non-null  float64\n",
      " 4   ZhanDVAR     680559 non-null  float64\n",
      " 5   TwoDvar      680073 non-null  float64\n",
      " 6   100RDVAR     677502 non-null  float64\n",
      " 7   MA5Anewhigh  716639 non-null  float64\n",
      " 8   high/dvar    674059 non-null  float64\n",
      " 9   MACDVdh      575582 non-null  float64\n",
      " 10  high/open    574390 non-null  float64\n",
      " 11  open/q       670809 non-null  float64\n",
      " 12  BuyWINLOSS   714280 non-null  float64\n",
      "dtypes: float64(10), object(3)\n",
      "memory usage: 71.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Dropping all the 'Label' columns because they only contain nan values and isn't useful.\n",
    "df_copy = df[df.columns.drop(list(df.filter(regex='Label')))]\n",
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_copy.drop(columns = ['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 402 entries, 248 to 714837\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Symbol       402 non-null    object \n",
      " 1   Date         402 non-null    object \n",
      " 2   ShortBuy     330 non-null    float64\n",
      " 3   ZhanDVAR     330 non-null    float64\n",
      " 4   TwoDvar      330 non-null    float64\n",
      " 5   100RDVAR     329 non-null    float64\n",
      " 6   MA5Anewhigh  340 non-null    float64\n",
      " 7   high/dvar    325 non-null    float64\n",
      " 8   MACDVdh      327 non-null    float64\n",
      " 9   high/open    328 non-null    float64\n",
      " 10  open/q       329 non-null    float64\n",
      " 11  BuyWINLOSS   396 non-null    float64\n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 40.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# only interested in rows where Shortbuy happnened. Hence dropping all rows where shortbuy=0\n",
    "df_clean1 = df_clean[df_clean.ShortBuy != 0]\n",
    "df_clean1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 402 entries, 248 to 714837\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Symbol       402 non-null    object \n",
      " 1   Date         402 non-null    object \n",
      " 2   ShortBuy     330 non-null    float64\n",
      " 3   ZhanDVAR     330 non-null    float64\n",
      " 4   TwoDvar      330 non-null    float64\n",
      " 5   100RDVAR     329 non-null    float64\n",
      " 6   MA5Anewhigh  340 non-null    float64\n",
      " 7   high/dvar    325 non-null    float64\n",
      " 8   MACDVdh      321 non-null    float64\n",
      " 9   high/open    328 non-null    float64\n",
      " 10  open/q       329 non-null    float64\n",
      " 11  BuyWINLOSS   396 non-null    float64\n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 40.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_clean2 = df_clean1.replace([np.inf, -np.inf], np.nan)\n",
    "df_clean2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean2.ShortBuy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 324 entries, 248 to 714837\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Symbol       324 non-null    object \n",
      " 1   Date         324 non-null    object \n",
      " 2   ShortBuy     324 non-null    float64\n",
      " 3   ZhanDVAR     324 non-null    float64\n",
      " 4   TwoDvar      324 non-null    float64\n",
      " 5   100RDVAR     323 non-null    float64\n",
      " 6   MA5Anewhigh  324 non-null    float64\n",
      " 7   high/dvar    322 non-null    float64\n",
      " 8   MACDVdh      315 non-null    float64\n",
      " 9   high/open    322 non-null    float64\n",
      " 10  open/q       323 non-null    float64\n",
      " 11  BuyWINLOSS   324 non-null    float64\n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 32.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows where ShortBuy and BuyWINLOSS are nans, ShortBuy is the data interested in, BuyWINLOSS is the y dependent variable.\n",
    "df_clean3 = df_clean2.dropna(how = 'any', subset = ['ShortBuy'])\n",
    "df_clean4 = df_clean3.dropna(how = 'any', subset = ['BuyWINLOSS'])\n",
    "df_clean4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shorbuy not needed for model training and calculations\n",
    "df_clean5 = df_clean4.drop(columns = ['ShortBuy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 324 entries, 248 to 714837\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Symbol       324 non-null    object \n",
      " 1   Date         324 non-null    object \n",
      " 2   ZhanDVAR     324 non-null    float64\n",
      " 3   TwoDvar      324 non-null    float64\n",
      " 4   100RDVAR     324 non-null    float64\n",
      " 5   MA5Anewhigh  324 non-null    float64\n",
      " 6   high/dvar    324 non-null    float64\n",
      " 7   MACDVdh      324 non-null    float64\n",
      " 8   high/open    324 non-null    float64\n",
      " 9   open/q       324 non-null    float64\n",
      " 10  BuyWINLOSS   324 non-null    float64\n",
      "dtypes: float64(9), object(2)\n",
      "memory usage: 30.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# filling the rest of the missing values with mean\n",
    "floatcol = list(df_clean5)\n",
    "floatcol = floatcol[2:]\n",
    "fill_mean = lambda col: col.fillna(col.mean()) if col.name in floatcol else col\n",
    "df_final = df_clean5.apply(fill_mean , axis=0)\n",
    "\n",
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepping data for modelling\n",
    "X = df_final.iloc[:, 2:-1].values\n",
    "y = df_final.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Building and Training Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=8, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=8, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "259/259 [==============================] - 0s 524us/sample - loss: 0.6833 - acc: 0.5830\n",
      "Epoch 2/100\n",
      "259/259 [==============================] - 0s 148us/sample - loss: 0.6741 - acc: 0.6139\n",
      "Epoch 3/100\n",
      "259/259 [==============================] - 0s 144us/sample - loss: 0.6695 - acc: 0.6293\n",
      "Epoch 4/100\n",
      "259/259 [==============================] - 0s 156us/sample - loss: 0.6648 - acc: 0.6255\n",
      "Epoch 5/100\n",
      "259/259 [==============================] - 0s 143us/sample - loss: 0.6619 - acc: 0.6371\n",
      "Epoch 6/100\n",
      "259/259 [==============================] - 0s 146us/sample - loss: 0.6595 - acc: 0.6332\n",
      "Epoch 7/100\n",
      "259/259 [==============================] - 0s 152us/sample - loss: 0.6573 - acc: 0.6371\n",
      "Epoch 8/100\n",
      "259/259 [==============================] - 0s 145us/sample - loss: 0.6559 - acc: 0.6409\n",
      "Epoch 9/100\n",
      "259/259 [==============================] - 0s 150us/sample - loss: 0.6543 - acc: 0.6409\n",
      "Epoch 10/100\n",
      "259/259 [==============================] - 0s 158us/sample - loss: 0.6535 - acc: 0.6293\n",
      "Epoch 11/100\n",
      "259/259 [==============================] - 0s 141us/sample - loss: 0.6520 - acc: 0.6216\n",
      "Epoch 12/100\n",
      "259/259 [==============================] - 0s 145us/sample - loss: 0.6516 - acc: 0.6293\n",
      "Epoch 13/100\n",
      "259/259 [==============================] - 0s 141us/sample - loss: 0.6499 - acc: 0.6293\n",
      "Epoch 14/100\n",
      "259/259 [==============================] - 0s 166us/sample - loss: 0.6487 - acc: 0.6216\n",
      "Epoch 15/100\n",
      "259/259 [==============================] - 0s 175us/sample - loss: 0.6483 - acc: 0.6332\n",
      "Epoch 16/100\n",
      "259/259 [==============================] - 0s 235us/sample - loss: 0.6478 - acc: 0.6216\n",
      "Epoch 17/100\n",
      "259/259 [==============================] - 0s 175us/sample - loss: 0.6459 - acc: 0.6332\n",
      "Epoch 18/100\n",
      "259/259 [==============================] - 0s 183us/sample - loss: 0.6447 - acc: 0.6255\n",
      "Epoch 19/100\n",
      "259/259 [==============================] - 0s 175us/sample - loss: 0.6446 - acc: 0.6293\n",
      "Epoch 20/100\n",
      "259/259 [==============================] - 0s 179us/sample - loss: 0.6432 - acc: 0.6332\n",
      "Epoch 21/100\n",
      "259/259 [==============================] - 0s 173us/sample - loss: 0.6434 - acc: 0.6293\n",
      "Epoch 22/100\n",
      "259/259 [==============================] - 0s 179us/sample - loss: 0.6419 - acc: 0.6293\n",
      "Epoch 23/100\n",
      "259/259 [==============================] - 0s 166us/sample - loss: 0.6411 - acc: 0.6293\n",
      "Epoch 24/100\n",
      "259/259 [==============================] - 0s 172us/sample - loss: 0.6400 - acc: 0.6332\n",
      "Epoch 25/100\n",
      "259/259 [==============================] - 0s 164us/sample - loss: 0.6390 - acc: 0.6293\n",
      "Epoch 26/100\n",
      "259/259 [==============================] - 0s 189us/sample - loss: 0.6385 - acc: 0.6216\n",
      "Epoch 27/100\n",
      "259/259 [==============================] - 0s 172us/sample - loss: 0.6372 - acc: 0.6293\n",
      "Epoch 28/100\n",
      "259/259 [==============================] - 0s 183us/sample - loss: 0.6364 - acc: 0.6409\n",
      "Epoch 29/100\n",
      "259/259 [==============================] - 0s 154us/sample - loss: 0.6368 - acc: 0.6409\n",
      "Epoch 30/100\n",
      "259/259 [==============================] - 0s 181us/sample - loss: 0.6351 - acc: 0.6332\n",
      "Epoch 31/100\n",
      "259/259 [==============================] - 0s 185us/sample - loss: 0.6334 - acc: 0.6332\n",
      "Epoch 32/100\n",
      "259/259 [==============================] - 0s 177us/sample - loss: 0.6323 - acc: 0.6293\n",
      "Epoch 33/100\n",
      "259/259 [==============================] - 0s 170us/sample - loss: 0.6314 - acc: 0.6371\n",
      "Epoch 34/100\n",
      "259/259 [==============================] - 0s 187us/sample - loss: 0.6311 - acc: 0.6409\n",
      "Epoch 35/100\n",
      "259/259 [==============================] - 0s 162us/sample - loss: 0.6298 - acc: 0.6371\n",
      "Epoch 36/100\n",
      "259/259 [==============================] - 0s 154us/sample - loss: 0.6290 - acc: 0.6525\n",
      "Epoch 37/100\n",
      "259/259 [==============================] - 0s 143us/sample - loss: 0.6289 - acc: 0.6486\n",
      "Epoch 38/100\n",
      "259/259 [==============================] - 0s 156us/sample - loss: 0.6271 - acc: 0.6409\n",
      "Epoch 39/100\n",
      "259/259 [==============================] - 0s 143us/sample - loss: 0.6257 - acc: 0.6486\n",
      "Epoch 40/100\n",
      "259/259 [==============================] - 0s 137us/sample - loss: 0.6254 - acc: 0.6486\n",
      "Epoch 41/100\n",
      "259/259 [==============================] - 0s 139us/sample - loss: 0.6245 - acc: 0.6448\n",
      "Epoch 42/100\n",
      "259/259 [==============================] - 0s 135us/sample - loss: 0.6237 - acc: 0.6486\n",
      "Epoch 43/100\n",
      "259/259 [==============================] - 0s 145us/sample - loss: 0.6227 - acc: 0.6486\n",
      "Epoch 44/100\n",
      "259/259 [==============================] - 0s 137us/sample - loss: 0.6209 - acc: 0.6525\n",
      "Epoch 45/100\n",
      "259/259 [==============================] - 0s 139us/sample - loss: 0.6204 - acc: 0.6525\n",
      "Epoch 46/100\n",
      "259/259 [==============================] - 0s 143us/sample - loss: 0.6199 - acc: 0.6486\n",
      "Epoch 47/100\n",
      "259/259 [==============================] - 0s 137us/sample - loss: 0.6196 - acc: 0.6486\n",
      "Epoch 48/100\n",
      "259/259 [==============================] - 0s 139us/sample - loss: 0.6182 - acc: 0.6564\n",
      "Epoch 49/100\n",
      "259/259 [==============================] - 0s 137us/sample - loss: 0.6172 - acc: 0.6525\n",
      "Epoch 50/100\n",
      "259/259 [==============================] - 0s 145us/sample - loss: 0.6153 - acc: 0.6564\n",
      "Epoch 51/100\n",
      "259/259 [==============================] - 0s 146us/sample - loss: 0.6148 - acc: 0.6602\n",
      "Epoch 52/100\n",
      "259/259 [==============================] - 0s 143us/sample - loss: 0.6135 - acc: 0.6564\n",
      "Epoch 53/100\n",
      "259/259 [==============================] - 0s 145us/sample - loss: 0.6124 - acc: 0.6564\n",
      "Epoch 54/100\n",
      "259/259 [==============================] - 0s 135us/sample - loss: 0.6122 - acc: 0.6641\n",
      "Epoch 55/100\n",
      "259/259 [==============================] - 0s 141us/sample - loss: 0.6124 - acc: 0.6641\n",
      "Epoch 56/100\n",
      "259/259 [==============================] - 0s 141us/sample - loss: 0.6107 - acc: 0.6602\n",
      "Epoch 57/100\n",
      "259/259 [==============================] - 0s 145us/sample - loss: 0.6093 - acc: 0.6680\n",
      "Epoch 58/100\n",
      "259/259 [==============================] - 0s 143us/sample - loss: 0.6084 - acc: 0.6564\n",
      "Epoch 59/100\n",
      "259/259 [==============================] - 0s 148us/sample - loss: 0.6075 - acc: 0.6680\n",
      "Epoch 60/100\n",
      "259/259 [==============================] - 0s 141us/sample - loss: 0.6070 - acc: 0.6680\n",
      "Epoch 61/100\n",
      "259/259 [==============================] - 0s 137us/sample - loss: 0.6059 - acc: 0.6680\n",
      "Epoch 62/100\n",
      "259/259 [==============================] - 0s 168us/sample - loss: 0.6042 - acc: 0.6680\n",
      "Epoch 63/100\n",
      "259/259 [==============================] - 0s 145us/sample - loss: 0.6044 - acc: 0.6718\n",
      "Epoch 64/100\n",
      "259/259 [==============================] - 0s 154us/sample - loss: 0.6037 - acc: 0.6834\n",
      "Epoch 65/100\n",
      "259/259 [==============================] - 0s 145us/sample - loss: 0.6018 - acc: 0.6873\n",
      "Epoch 66/100\n",
      "259/259 [==============================] - 0s 141us/sample - loss: 0.6006 - acc: 0.6834\n",
      "Epoch 67/100\n",
      "259/259 [==============================] - 0s 143us/sample - loss: 0.6005 - acc: 0.6911\n",
      "Epoch 68/100\n",
      "259/259 [==============================] - 0s 141us/sample - loss: 0.5997 - acc: 0.6950\n",
      "Epoch 69/100\n",
      "259/259 [==============================] - 0s 139us/sample - loss: 0.5985 - acc: 0.6950\n",
      "Epoch 70/100\n",
      "259/259 [==============================] - 0s 135us/sample - loss: 0.5975 - acc: 0.6950\n",
      "Epoch 71/100\n",
      "259/259 [==============================] - 0s 139us/sample - loss: 0.5971 - acc: 0.6911\n",
      "Epoch 72/100\n",
      "259/259 [==============================] - 0s 143us/sample - loss: 0.5970 - acc: 0.6988\n",
      "Epoch 73/100\n",
      "259/259 [==============================] - 0s 139us/sample - loss: 0.5952 - acc: 0.7027\n",
      "Epoch 74/100\n",
      "259/259 [==============================] - 0s 148us/sample - loss: 0.5949 - acc: 0.6950\n",
      "Epoch 75/100\n",
      "259/259 [==============================] - 0s 135us/sample - loss: 0.5946 - acc: 0.6988\n",
      "Epoch 76/100\n",
      "259/259 [==============================] - 0s 141us/sample - loss: 0.5924 - acc: 0.6950\n",
      "Epoch 77/100\n",
      "259/259 [==============================] - 0s 141us/sample - loss: 0.5918 - acc: 0.6988\n",
      "Epoch 78/100\n",
      "259/259 [==============================] - 0s 189us/sample - loss: 0.5921 - acc: 0.6988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "259/259 [==============================] - 0s 187us/sample - loss: 0.5903 - acc: 0.7027\n",
      "Epoch 80/100\n",
      "259/259 [==============================] - 0s 148us/sample - loss: 0.5889 - acc: 0.7104\n",
      "Epoch 81/100\n",
      "259/259 [==============================] - 0s 139us/sample - loss: 0.5886 - acc: 0.7027\n",
      "Epoch 82/100\n",
      "259/259 [==============================] - 0s 141us/sample - loss: 0.5874 - acc: 0.7027\n",
      "Epoch 83/100\n",
      "259/259 [==============================] - 0s 135us/sample - loss: 0.5868 - acc: 0.7066\n",
      "Epoch 84/100\n",
      "259/259 [==============================] - 0s 146us/sample - loss: 0.5856 - acc: 0.7027\n",
      "Epoch 85/100\n",
      "259/259 [==============================] - 0s 166us/sample - loss: 0.5843 - acc: 0.7066\n",
      "Epoch 86/100\n",
      "259/259 [==============================] - 0s 156us/sample - loss: 0.5859 - acc: 0.7027\n",
      "Epoch 87/100\n",
      "259/259 [==============================] - 0s 162us/sample - loss: 0.5823 - acc: 0.7066\n",
      "Epoch 88/100\n",
      "259/259 [==============================] - 0s 139us/sample - loss: 0.5823 - acc: 0.7066\n",
      "Epoch 89/100\n",
      "259/259 [==============================] - 0s 168us/sample - loss: 0.5811 - acc: 0.7027\n",
      "Epoch 90/100\n",
      "259/259 [==============================] - 0s 150us/sample - loss: 0.5806 - acc: 0.7066\n",
      "Epoch 91/100\n",
      "259/259 [==============================] - 0s 156us/sample - loss: 0.5787 - acc: 0.7066\n",
      "Epoch 92/100\n",
      "259/259 [==============================] - 0s 158us/sample - loss: 0.5789 - acc: 0.7143\n",
      "Epoch 93/100\n",
      "259/259 [==============================] - 0s 146us/sample - loss: 0.5769 - acc: 0.7104\n",
      "Epoch 94/100\n",
      "259/259 [==============================] - 0s 146us/sample - loss: 0.5768 - acc: 0.7066\n",
      "Epoch 95/100\n",
      "259/259 [==============================] - 0s 141us/sample - loss: 0.5752 - acc: 0.7104\n",
      "Epoch 96/100\n",
      "259/259 [==============================] - 0s 141us/sample - loss: 0.5750 - acc: 0.7143\n",
      "Epoch 97/100\n",
      "259/259 [==============================] - 0s 141us/sample - loss: 0.5761 - acc: 0.7143\n",
      "Epoch 98/100\n",
      "259/259 [==============================] - 0s 139us/sample - loss: 0.5729 - acc: 0.7104\n",
      "Epoch 99/100\n",
      "259/259 [==============================] - 0s 145us/sample - loss: 0.5724 - acc: 0.7066\n",
      "Epoch 100/100\n",
      "259/259 [==============================] - 0s 160us/sample - loss: 0.5704 - acc: 0.7143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d65c62e5f8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 5, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8 21]\n",
      " [ 8 28]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Random Forest Classification model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9 20]\n",
      " [ 5 31]]\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred1)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.11 %\n",
      "Standard Deviation: 6.75 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(estimator = classifier, X= X_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracy.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracy.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature importance in RandomForest Classifier\n",
    "col = ['ZhanDVAR', 'TwoDvar', '100RDVAR', 'MA5Anewhigh', 'high/dvar', \n",
    "       'MACDVdh', 'high/open', 'open/q']\n",
    "#modelname.feature_importance_\n",
    "imp = classifier.feature_importances_\n",
    "#plot\n",
    "fig, ax = plt.subplots() \n",
    "width = 0.4 # the width of the bars \n",
    "ind = np.arange(len(imp)) # the x locations for the groups\n",
    "ax.barh(ind, imp, width, color='green')\n",
    "ax.set_yticks(ind+width/10)\n",
    "ax.set_yticklabels(col, minor=False)\n",
    "plt.title('Feature importance in RandomForest Classifier')\n",
    "plt.xlabel('Relative importance')\n",
    "plt.ylabel('feature') \n",
    "plt.figure(figsize=(5,5))\n",
    "fig.set_size_inches(6.5, 4.5, forward=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
